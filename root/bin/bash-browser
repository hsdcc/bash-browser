#!/bin/bash

get_term_size() {
  # This uses an alternative escape sequence (\e[18t) to get terminal size,
  # which has proven to be more reliable.
  # Response format: \e[8;<height>;<width>t
  printf '\e[18t' >/dev/tty

  local response
  read -s -t 1 -d t response </dev/tty

  if [[ -n "$response" && "$response" == *";"* && "$response" == *"8;"* ]]; then
    response=${response#*;} # Remove leading junk up to first ;
    term_height=${response%;*}
    term_width=${response#*;} # Remove leading junk up to first ;
  fi

  # Fallback if detection fails
  term_height=${term_height:-24}
  term_width=${term_width:-80}
}

if [ $# -eq 0 ]; then
  echo "usage: bash-browser <url>"
  exit 1
fi

url="$1"
echo "loading..."

echo "fetching: $url"

# Use the curl script to download content
content="$("/home/meow/code/bash-browser/root/bin/curl" "$url")"
if [ $? -ne 0 ]; then
  echo "error: could not fetch content from $url"
  exit 1
fi

# Basic HTML tag stripping and decoding, optimized to run on the whole content at once.

# 1. Remove HTML comments using pure bash
# This is still iterative, but runs on the whole buffer, not line-by-line
while [[ "$content" == *"<!--"*"-->"* ]]; do
  start_comment="${content%%<!--*}"
  end_comment="${content#*-->}"
  content="${start_comment}${end_comment}"
done

# 1.5. Process <a> tags to make links visible: <a href="URL">TEXT</a> -> TEXT [URL]
# Since HTML tags can span multiple lines, we'll convert to single line temporarily, process, then restore
# Use a unique marker that won't appear in HTML content

LINE_MARKER="___BASHBROWSER_LINEBREAK___"

# Convert newlines to markers to allow multi-line pattern matching
temp_content="${content//$'\n'/$LINE_MARKER}"

# Process <A HREF= tags (upper case)
# Since newlines are converted to markers, we need to find <A that might have markers before attributes
# This pattern now looks for <A followed by any amount of content (including markers) to HREF=
original_temp="$temp_content"
while [[ "$temp_content" == *"<A"* ]]; do
  # Find the complete opening tag structure by looking for <A, then everything up to the first >, then content to </A>
  if [[ "$temp_content" != *"<A"*">"*"</A>"* ]]; then
    break  # No complete <A>...</A> tag found
  fi
  
  before_a="${temp_content%%<A*}"
  after_a="${temp_content#*<A}"
  
  # Get the part up to first > (the tag attributes) and part after > (the content)
  if [[ "$after_a" != *">"* ]]; then
    break  # No closing > found
  fi
  
  tag_attrs_part="${after_a%%>*}"
  content_after_opening="${after_a#*>}"
  
  # Check if HREF exists in the tag attributes
  if [[ "$tag_attrs_part" == *"HREF="* ]]; then
    # Extract the href URL
    after_href="${tag_attrs_part#*HREF=}"
    quote_char="${after_href:0:1}"
    
    if [[ "$quote_char" == '"' || "$quote_char" == "'" ]]; then
      url_part="${after_href:1}"
      url="${url_part%%"$quote_char"*}"
    else
      url="${after_href%%[[:space:]>\<]*}"
    fi
    
    # Now find the content within the tag and the part after closing </A>
    if [[ "$content_after_opening" != *"</A>"* ]]; then
      break  # No closing </A> found
    fi
    
    anchor_content="${content_after_opening%%</A>*}"
    after_closing="${content_after_opening#*</A>}"
    
    # Construct the replacement
    full_opening_tag="<A${tag_attrs_part}>"
    full_pattern="${full_opening_tag}${anchor_content}</A>"
    replacement="${anchor_content} [${url}]"
    
    temp_content="${temp_content/"$full_pattern"/"$replacement"}"
  else
    # No HREF in this tag, break to avoid infinite loop
    break
  fi
  
  # Prevent infinite loop
  if [[ "$temp_content" == "$original_temp" ]]; then
    break
  fi
  original_temp="$temp_content"
done

# Process <a href= tags (lower case) similarly
original_temp="$temp_content"
while [[ "$temp_content" == *"<a"* ]]; do
  if [[ "$temp_content" != *"<a"*">"*"</a>"* ]]; then
    break
  fi
  
  before_a="${temp_content%%<a*}"
  after_a="${temp_content#*<a}"
  
  if [[ "$after_a" != *">"* ]]; then
    break
  fi
  
  tag_attrs_part="${after_a%%>*}"
  content_after_opening="${after_a#*>}"
  
  if [[ "$tag_attrs_part" == *"href="* ]]; then
    after_href="${tag_attrs_part#*href=}"
    quote_char="${after_href:0:1}"
    
    if [[ "$quote_char" == '"' || "$quote_char" == "'" ]]; then
      url_part="${after_href:1}"
      url="${url_part%%"$quote_char"*}"
    else
      url="${after_href%%[[:space:]>\<]*}"
    fi
    
    if [[ "$content_after_opening" != *"</a>"* ]]; then
      break
    fi
    
    anchor_content="${content_after_opening%%</a>*}"
    after_closing="${content_after_opening#*</a>}"
    
    full_opening_tag="<a${tag_attrs_part}>"
    full_pattern="${full_opening_tag}${anchor_content}</a>"
    replacement="${anchor_content} [${url}]"
    
    temp_content="${temp_content/"$full_pattern"/"$replacement"}"
  else
    break
  fi
  
  if [[ "$temp_content" == "$original_temp" ]]; then
    break
  fi
  original_temp="$temp_content"
done

# Convert back from markers to actual newlines
content="${temp_content//$LINE_MARKER/$'\n'}"

# 2. Replace certain closing tags with newlines before removing all other tags
# Handle h1-h6 tags
content="${content//<\/h1>/$'\n'$'\n'}"
content="${content//<\/h2>/$'\n'$'\n'}"
content="${content//<\/h3>/$'\n'$'\n'}"
content="${content//<\/h4>/$'\n'$'\n'}"
content="${content//<\/h5>/$'\n'$'\n'}"
content="${content//<\/h6>/$'\n'$'\n'}"
# Other block-level tags
content="${content//<\/p>/$'\n'$'\n'}"
content="${content//<br>/$'\n'}"
content="${content//<br\/>/$'\n'}"
content="${content//<br \/>/$'\n'}"
content="${content//<\/li>/$'\n'}"
content="${content//<\/div>/$'\n'}"
content="${content//<\/tr>/$'\n'}"
content="${content//<\/td>/	}" # tab character
content="${content//<\/th>/	}" # tab character

# 3. Remove all remaining HTML tags iteratively
# This is the main bottleneck, but necessary for correctness in pure bash
while [[ "$content" == *"<"*">"* ]]; do
  start_part="${content%%<*}"
  remaining="${content#*>}"
  content="${start_part}${remaining}"
done

# 4. Decode common HTML entities
content="${content//&amp;/&}"
content="${content//&lt;/<}"
content="${content//&gt;/>}"
content="${content//&quot;/\"}"
content="${content//&#39;/\'}"

# 5. Clean up extra blank lines
# The previous steps can create lots of consecutive newlines, this collapses them.
# Replace three or more newlines with two.
while [[ "$content" == *$'\n\n\n'* ]]; do
  content="${content//$'\n\n\n'/$'\n\n'}"
done

# --- scrolling implementation ---

follow_links() {
  local visible_links=()
  local link_positions=()
  local hint_chars="asdfjklgh"
  declare -A hint_lookup

  # Pattern to find http(s) URLs, excluding common trailing characters
  local url_pattern='https?://[^][<>"[:space:]]*'
  
  # Pattern to find [URL] style links created from HTML <a> tags
  local bracket_url_pattern='\[([^]]*)\]'

  for ((i = 0; i < view_height; i++)); do
    local line_index=$((offset + i))
    [ $line_index -ge $line_count ] && break

    local line_content="${lines[$line_index]}"
    local col_offset=0

    # First look for http(s) URLs
    while [[ "$line_content" =~ $url_pattern ]]; do
      local url="${BASH_REMATCH[0]}"
      local pre_match="${line_content%%"$url"*}"
      local col=$((col_offset + ${#pre_match} + 1))

      visible_links+=("$url")
      link_positions+=("$((i + 1));$col")

      local consumed_part="${pre_match}${url}"
      line_content="${line_content#"${consumed_part}"}"
      col_offset=$((col_offset + ${#consumed_part}))
    done
    
    # Reset line content to look for bracket URLs 
    line_content="${lines[$line_index]}"
    col_offset=0
    
    # Then look for bracket-style URLs like [WhatIs.html]
    while [[ "$line_content" =~ $bracket_url_pattern ]]; do
      # Extract the URL between brackets
      local full_match="${BASH_REMATCH[0]}"
      local url="${BASH_REMATCH[1]}"
      
      local pre_match="${line_content%%"$full_match"*}"
      local col=$((col_offset + ${#pre_match} + 1))

      visible_links+=("$url")
      link_positions+=("$((i + 1));$col")

      local consumed_part="${pre_match}${full_match}"
      line_content="${line_content#"${consumed_part}"}"
      col_offset=$((col_offset + ${#consumed_part}))
    done
  done

  if [ ${#visible_links[@]} -eq 0 ]; then
    printf "\e[${height};0H\e[41m"
    printf "%-${term_width}s" "No links found on screen."
    printf "\e[0m"
    sleep 1
    return
  fi

  for i in "${!visible_links[@]}"; do
    local pos="${link_positions[$i]}"
    local screen_line="${pos%%;*}"
    local screen_col="${pos#*;}"
    local hint_char="${hint_chars:$i:1}"

    [ -z "$hint_char" ] && break

    hint_lookup["$hint_char"]="$i"

    printf "\e[%s;%sH\e[42;30m[%s]\e[0m" "$screen_line" "$screen_col" "$hint_char"
  done

  printf "\e[${height};0H\e[44m"
  printf "%-${term_width}s" "Type hint to follow link, or any other key to cancel."
  printf "\e[0m"

  read -s -n 1 key

  local link_index="${hint_lookup[$key]}"
  if [[ -n "$link_index" ]]; then
    local target_url="${visible_links[$link_index]}"

    printf "\e[?25h\033c"

    # Handle different types of relative URLs
    if [[ "$target_url" != "http"* && "$target_url" != "https"* ]]; then
      # Get the base URL components
      local original_url="$url"
      local protocol="${original_url%%://*}"
      local after_protocol="${original_url#*://}"
      local host="${after_protocol%%/*}"
      local current_path
      
      # Check if there is a path component
      if [[ "$after_protocol" == *"/"* ]]; then
        current_path="/${after_protocol#*/}"
      else
        current_path="/"
      fi

      if [[ "$target_url" == //* ]]; then
        # Protocol-relative URL, e.g. //example.com/path
        target_url="${protocol}:${target_url}"
      elif [[ "$target_url" == /* ]]; then
        # Root-relative URL, e.g. /path/to/file
        target_url="${protocol}://${host}${target_url}"
      else
        # Document-relative URL, e.g. other.html or ../other.html

        # Get the directory of the current path
        local base_path
        if [[ "$current_path" == */ ]]; then
          base_path="$current_path"
        else
          base_path="${current_path%/*}/"
        fi

        # Combine base path with target url
        local new_path="${base_path}${target_url}"

        # Normalize the path (handle .. and .)
        local OIFS="$IFS"
        IFS='/'
        read -ra path_parts <<< "$new_path"
        IFS="$OIFS"

        local normalized_parts=()
        for part in "${path_parts[@]}"; do
          if [[ -z "$part" || "$part" == "." ]]; then
            continue
          fi
          if [[ "$part" == ".." ]]; then
            if [ ${#normalized_parts[@]} -gt 0 ]; then
              normalized_parts=("${normalized_parts[@]:0:${#normalized_parts[@]}-1}")
            fi
          else
            normalized_parts+=("$part")
          fi
        done
        
        local final_path
        if [ ${#normalized_parts[@]} -eq 0 ]; then
            final_path="/"
        else
            OIFS="$IFS"
            IFS='/'
            final_path="/${normalized_parts[*]}"
            IFS="$OIFS"
        fi

        target_url="${protocol}://${host}${final_path}"
      fi
    fi

    exec "$0" "$target_url"
  fi
  # If key is not a valid hint, we do nothing and the main loop will redraw the screen.
}

# store content in an array
mapfile -t lines <<<"$content"

# get terminal size
get_term_size
height=${term_height}

# leave room for status bar
view_height=$((height - 1))

offset=0
line_count=${#lines[@]}

# hide cursor
printf "\e[?25l"

while true; do
  # clear screen
  printf "\033c"

  # display content
  for ((i = 0; i < view_height; i++)); do
    line_index=$((offset + i))
    if [ $line_index -lt $line_count ]; then
      echo "${lines[$line_index]}"
    fi
  done

  # status bar
  printf "\e[${height};0H" # move to last line
  printf "\e[44m"          # blue background
  status_text=$(printf "%s" "$url")
  printf "%-${term_width}s" "$status_text" # pad to full width
  printf "\e[0m"                           # reset color

  # get user input
  read -s -n 1 key

  case "$key" in
  'q')
    break
    ;;
  'j')
    # scroll down
    if [ $((offset + view_height)) -lt $line_count ]; then
      offset=$((offset + 1))
    fi
    ;;
  'k')
    # scroll up
    if [ $offset -gt 0 ]; then
      offset=$((offset - 1))
    fi
    ;;
  's')
    follow_links
    ;;
  esac
done

# show cursor and clear screen on exit
printf "\e[?25h"
printf "\033c"
